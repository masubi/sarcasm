{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.0.0b1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41001812,
     "status": "ok",
     "timestamp": 1570702940111,
     "user": {
      "displayName": "Justin Masui",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAqYNd35ntJR-uokWv_ZbHVaZ0hDMLz_PCI21XWqNM=s64",
      "userId": "13872986104507877375"
     },
     "user_tz": 420
    },
    "id": "jGwXGIXvFhXW",
    "outputId": "e31a13f3-6c0e-43fd-98d9-d49e41bb5ef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import *\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "training_size = 1990000\n",
    "batch_size=32\n",
    "epochs=50\n",
    "\n",
    "version=4\n",
    "download_data=False\n",
    "load_weights=False\n",
    "do_training=True\n",
    "save_model=True\n",
    "model_name=\"sarcasm_model\"+\"_v\"+str(version)\n",
    "model_file=model_name+\".h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------\n",
    "# Get Data\n",
    "#-------------------\n",
    "\n",
    "sentences = []\n",
    "context = []\n",
    "labels = []\n",
    "urls = []\n",
    "\n",
    "# sarcasm_data.json\n",
    "if(download_data):\n",
    "    !wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json \\\n",
    "    -O /tmp/sarcasm.json               \n",
    "        \n",
    "def clean_line(line):\n",
    "    try:\n",
    "        line.lower()\n",
    "    except:\n",
    "        print(\"failed to lower: \"+str(line))            \n",
    "    \n",
    "    line = \" \".join(line.split())\n",
    "    line = line.strip()\n",
    "    line = line.replace(\"[_-]\", ' ')\n",
    "    line = line.replace(\"\\'\", '')\n",
    "    line = line.replace(\"at&amp;t\", \"at&t\")\n",
    "                        \n",
    "    return line\n",
    "        \n",
    "def parseJsonToMemory(filename, labelField, commentField, contextField):\n",
    "    print(f'Processing {filename}')\n",
    "    with open(\"./data/sarcasm_data.json\", 'r') as f:\n",
    "        datastore = json.load(f)\n",
    "\n",
    "        for item in datastore:\n",
    "            sentences.append(item[commentField])\n",
    "            labels.append(int(item[labelField]))\n",
    "            if contextField == -1 :\n",
    "                context.append(\"\")\n",
    "            else:\n",
    "                context.append(row[contextField])\n",
    "    print(f'Processed {filename}')\n",
    "    print(\"  sentences len: \"+str(len(sentences)))\n",
    "    print(\"  labels len: \"+str(len(labels)))\n",
    "    print(\"  context len: \"+str(len(context)))\n",
    "    \n",
    "def joinArray(arr):\n",
    "    s = \" \"\n",
    "    s = s.join(arr)\n",
    "    return s\n",
    "\n",
    "def parseJsonToMemory2(filename, labelField, commentField, contextField):\n",
    "    print(f'Processing {filename}')\n",
    "    with open(\"./data/sarcasm_data.json\", 'r') as f:\n",
    "        datastore = json.load(f)\n",
    "\n",
    "        for item in datastore:\n",
    "            sentences.append(item[commentField])\n",
    "            labels.append(int(item[labelField]))\n",
    "            context.append(joinArray(item[contextField]))\n",
    "            \n",
    "    print(f'Processed {filename}')\n",
    "    print(\"  sentences len: \"+str(len(sentences)))\n",
    "    print(\"  labels len: \"+str(len(labels)))\n",
    "    print(\"  context len: \"+str(len(context)))\n",
    "  \n",
    "import csv \n",
    "def parseCSVToMemory(filename, labelCol, commentCol, contextCol):\n",
    "    print(f'Processing {filename}')\n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            #print(f'\\t label: {row[labelCol]} of {type(row[labelCol])} sentence: {row[commentCol]} context: {row[contextCol]}')\n",
    "            try:\n",
    "                if line_count == 0:\n",
    "                    print(f'  Column names are {\", \".join(row)}')\n",
    "                    line_count += 1\n",
    "                else:\n",
    "                    \n",
    "                    labels.append(int(row[labelCol]))\n",
    "                    sentences.append(row[commentCol])\n",
    "                    line_count += 1\n",
    "                    if contextCol == -1 :\n",
    "                        context.append(\"\")\n",
    "                    else:\n",
    "                        context.append(row[contextCol])               \n",
    "            except:\n",
    "                print(\"error parsing label: \" + row[labelCol] + \" comment: \" + row[commentCol])        \n",
    "        print(f'Processed {filename} w/ {line_count} lines.')\n",
    "        print(\"  sentences len: \"+str(len(sentences)))\n",
    "        print(\"  labels len: \"+str(len(labels)))\n",
    "        print(\"  context len: \"+str(len(context)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./data/sarcasm_data.json\n",
      "Processed ./data/sarcasm_data.json\n",
      "  sentences len: 26709\n",
      "  labels len: 26709\n",
      "  context len: 26709\n",
      "Processing ./data/sarcasm_kaggle.csv\n",
      "  Column names are label, comment\n",
      "Processed ./data/sarcasm_kaggle.csv w/ 1010819 lines.\n",
      "  sentences len: 1037527\n",
      "  labels len: 1037527\n",
      "  context len: 1037527\n",
      "Processing ./data/train-balanced-sarcasm.csv\n",
      "  Column names are label, comment, author, subreddit, score, ups, downs, date, created_utc, parent_comment\n",
      "Processed ./data/train-balanced-sarcasm.csv w/ 1010827 lines.\n",
      "  sentences len: 2048353\n",
      "  labels len: 2048353\n",
      "  context len: 2048353\n",
      "done processing\n"
     ]
    }
   ],
   "source": [
    "# add class data\n",
    "parseJsonToMemory('./data/sarcasm_data.json', 'is_sarcastic', 'headline', -1)\n",
    "\n",
    "#add kaggle data\n",
    "parseCSVToMemory('./data/sarcasm_kaggle.csv', 0, 1, -1)\n",
    "\n",
    "#add reddit data\n",
    "parseCSVToMemory('./data/train-balanced-sarcasm.csv', 0, 1, 9)\n",
    "\n",
    "\n",
    "#TODO: doesn't parse correctly\n",
    "#parseJsonToMemory2('./data/sarcasm_data_mustard.json', \"sarcasm\", \"utterance\", \"context\") \n",
    "\n",
    "# shuffle\n",
    "\n",
    "# combine x and y cols\n",
    "def concat_cols(x,y):\n",
    "    y = y.reshape(y.shape[0],1)\n",
    "    return np.concatenate((x,y), axis=1)\n",
    "\n",
    "# split x and y\n",
    "def split_cols(a):\n",
    "    x_res = a[:,0:a.shape[1]-1]\n",
    "    y_res = a[:,a.shape[1]-1:a.shape[1]]\n",
    "    return x_res, y_res\n",
    "\n",
    "# shuffle rows of a\n",
    "def shuffle(a, subset_size):\n",
    "    subset = a[np.random.choice(a.shape[0], subset_size, replace=False), :]\n",
    "    return subset\n",
    "                  \n",
    "print(\"done processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41001812,
     "status": "ok",
     "timestamp": 1570702940111,
     "user": {
      "displayName": "Justin Masui",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAqYNd35ntJR-uokWv_ZbHVaZ0hDMLz_PCI21XWqNM=s64",
      "userId": "13872986104507877375"
     },
     "user_tz": 420
    },
    "id": "jGwXGIXvFhXW",
    "outputId": "e31a13f3-6c0e-43fd-98d9-d49e41bb5ef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I think I'm ok with a very spartan environment, tbh.\", 'Lawl', \"I know people who didn't stick with MD/PhD programs (eg only ended up with a MD/MS) who see themselves as quitters or failures.\", 'Today, I miss Ba.', 'Lol yeah he tends to do that sometimes.']\n",
      "[0, 0, 0, 0, 0]\n",
      "training_padded.shape: (1990000, 120)\n",
      "[[2129    1  875 ...    0    0    0]\n",
      " [   2    1    1 ...    0    0    0]\n",
      " [ 813 1019    4 ...    0    0    0]\n",
      " ...\n",
      " [  31 1011  218 ...    0    0    0]\n",
      " [  13 2769    1 ...    0    0    0]\n",
      " [2834   20   83 ...    0    0    0]]\n",
      "<class 'numpy.ndarray'>\n",
      "testing_padded.shape: (58353, 120)\n",
      "<class 'numpy.ndarray'>\n",
      "type of test labels: <class 'list'>\n",
      "type of training labels: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "training_sentences = sentences[0:training_size]\n",
    "testing_sentences = sentences[training_size:]\n",
    "training_labels = labels[0:training_size]\n",
    "testing_labels = labels[training_size:]\n",
    "print(testing_sentences[0:5])\n",
    "print(testing_labels[0:5])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "def sentencesToPaddedSequences(sentences):\n",
    "    sequences = tokenizer.texts_to_sequences(sentences)\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "    return padded_sequences\n",
    "\n",
    "training_padded = sentencesToPaddedSequences(training_sentences)\n",
    "print(\"training_padded.shape: \"+str(training_padded.shape))\n",
    "print(str(training_padded))\n",
    "print(type(training_padded))\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = sentencesToPaddedSequences(testing_sentences)\n",
    "print(\"testing_padded.shape: \"+str(testing_padded.shape))\n",
    "print(type(testing_padded))\n",
    "\n",
    "print(\"type of test labels: \" + str(type(testing_labels)))\n",
    "print(\"type of training labels: \" + str(type(training_labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41001812,
     "status": "ok",
     "timestamp": 1570702940111,
     "user": {
      "displayName": "Justin Masui",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAqYNd35ntJR-uokWv_ZbHVaZ0hDMLz_PCI21XWqNM=s64",
      "userId": "13872986104507877375"
     },
     "user_tz": 420
    },
    "id": "jGwXGIXvFhXW",
    "outputId": "e31a13f3-6c0e-43fd-98d9-d49e41bb5ef2"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(load_weights):\n",
    "    print(\"loading weights from: \"+model_file)\n",
    "    model.load_weights(model_file)\n",
    "    print(\"weights: \")\n",
    "    #print(str(model.get_weights()))\n",
    "    print(\"loading weights complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41001812,
     "status": "ok",
     "timestamp": 1570702940111,
     "user": {
      "displayName": "Justin Masui",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAqYNd35ntJR-uokWv_ZbHVaZ0hDMLz_PCI21XWqNM=s64",
      "userId": "13872986104507877375"
     },
     "user_tz": 420
    },
    "id": "jGwXGIXvFhXW",
    "outputId": "e31a13f3-6c0e-43fd-98d9-d49e41bb5ef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 120, 16)           160000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 120, 256)          148480    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 735,745\n",
      "Trainable params: 735,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41001812,
     "status": "ok",
     "timestamp": 1570702940111,
     "user": {
      "displayName": "Justin Masui",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAqYNd35ntJR-uokWv_ZbHVaZ0hDMLz_PCI21XWqNM=s64",
      "userId": "13872986104507877375"
     },
     "user_tz": 420
    },
    "id": "jGwXGIXvFhXW",
    "outputId": "e31a13f3-6c0e-43fd-98d9-d49e41bb5ef2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1990000 samples, validate on 58353 samples\n",
      "Epoch 1/50\n",
      "  64704/1990000 [..............................] - ETA: 4:21:30 - loss: 0.5941 - accuracy: 0.6811"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c7f3be2872f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                         verbose=1)\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3508\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3510\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    571\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='./'+model_name+'-weights.hdf5', verbose=2, save_best_only=True)\n",
    "\n",
    "if(do_training):\n",
    "    history = model.fit(training_padded, \n",
    "                        training_labels, \n",
    "                        batch_size=batch_size, \n",
    "                        epochs=epochs, \n",
    "                        validation_data=(testing_padded, testing_labels),\n",
    "                        callbacks=[checkpointer],\n",
    "                        verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13196981,
     "status": "ok",
     "timestamp": 1570648203202,
     "user": {
      "displayName": "Justin Masui",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAqYNd35ntJR-uokWv_ZbHVaZ0hDMLz_PCI21XWqNM=s64",
      "userId": "13872986104507877375"
     },
     "user_tz": 420
    },
    "id": "g9DC6dmLF8DC",
    "outputId": "61b16ddd-66ba-4d1c-d0ef-ee410d0f6b6f"
   },
   "outputs": [],
   "source": [
    "if(do_training):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    #print(str(history.history))\n",
    "    def plot_graphs(history, string):\n",
    "      plt.plot(history.history[string])\n",
    "      plt.plot(history.history['val_'+string])\n",
    "      plt.xlabel(\"Epochs\")\n",
    "      plt.ylabel(string)\n",
    "      plt.legend([string, 'val_'+string])\n",
    "      plt.show()\n",
    "\n",
    "    plot_graphs(history, 'accuracy')\n",
    "    plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZEZIUppGhdi"
   },
   "outputs": [],
   "source": [
    "if(save_model):\n",
    "    model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "\n",
    "x_pred_sentences = [\"that dress looks so cute on you\", \n",
    "                    \"jeans that make my butt look good\", \n",
    "                    \"phantom menace was the best movie ever\",\n",
    "                    \"i am so over it\",\n",
    "                    \"babies are ugly\",\n",
    "                    \"you are so badass\"]\n",
    "x_padded_sequence = sentencesToPaddedSequences(x_pred_sentences)\n",
    "pred = model.predict(x_padded_sequence)\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_w3_sarcasm_bi_lstm.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/Course%203%20-%20Week%203%20-%20Lesson%202.ipynb",
     "timestamp": 1570589102457
    },
    {
     "file_id": "1OOzqEhzmkFQOtmEGwMhiLxB_D2osx4eM",
     "timestamp": 1556803950670
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
